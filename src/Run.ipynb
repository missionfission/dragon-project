{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import yamlordereddictloader\n",
    "\n",
    "from torchvision import models\n",
    "from yaml import dump\n",
    "from dlrm.dlrm_s_pytorch import DLRM_Net, dash_separated_ints, dash_separated_floats\n",
    "from ir.handlers import handlers\n",
    "from ir.trace import trace\n",
    "from ir.trace import get_backprop_memory\n",
    "from utils.logger import create_logger\n",
    "from utils.visualizer import plot_descent\n",
    "from utils.visualizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scheduling import Scheduling\n",
    "from generator import Generator, get_mem_props, get_compute_props\n",
    "from generator import *\n",
    "from utils.visualizer import *\n",
    "from main import design_tech_runner, runner_save_all, design_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common_models import vggnet_graph, resnet_graph, bert_graph, gpt2_graph, dlrm_graph\n",
    "# print(\"=====================================VGG-Net=============================================\")\n",
    "vgg11_graph = vggnet_graph()\n",
    "design_tech_runner([vgg11_graph])\n",
    "\n",
    "# print(\"=====================================ResNet===============================================\")\n",
    "design_tech_runner([resnet_graph])\n",
    "dlrm_graph = dlrm_graph()\n",
    "# for node in dlrm_graph.nodes:\n",
    "#     print(node.in_edge_mem + node.mem_fetch + node.out_edge_mem, node.compute_expense )\n",
    "\n",
    "design_tech_runner([dlrm_graph])\n",
    "\n",
    "bert_graph_data = bert_graph()\n",
    "# runner_forward([bert_graph_data])\n",
    "gpt2_graph = gpt2_graph()\n",
    "design_tech_runner([gpt2_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gnn_model import gnn_graph\n",
    "from gan_model import gan_graph\n",
    "from dart_model import dart_graph\n",
    "from a3c_model import a3c_grah\n",
    "design_tech_runner([gnn_graph])\n",
    "design_tech_runner([dart_graph])\n",
    "design_tech_runner([a3c_graph]) # Actor Critic\n",
    "design_tech_runner([gan_graph]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scheduler = Scheduling()\n",
    "# time_list, bandwidth_time_list, mem_size_idle_time_list, bank_list, mem_size_list, compute_list, tech_params = design_tech_runner([vgg11_graph], scheduler)\n",
    "# plot_descent(time_list, bandwidth_time_list, mem_size_idle_time_list)\n",
    "# print(tech_params)\n",
    "# # Plot Design Parameters change over time\n",
    "# plot_design_param_change(bank_list, mem_size_list, compute_list)\n",
    "# # Plot Technology Parameters change over time\n",
    "# plot_tech_param_change(np.transpose(np.array(tech_params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## TODO Check this out something really weird going on with DLRM's \n",
    "# for j in range(0,5):\n",
    "#     for i in range(5,15):\n",
    "#         scheduler = Scheduling()\n",
    "#         scheduler.config[\"memory\"][\"level1\"][\"frequency\"]=5\n",
    "#         scheduler.config[\"memory\"][\"level1\"][\"frequency\"]*=2**j\n",
    "#         memory = scheduler.config[\"memory\"][\"level1\"]\n",
    "#         scheduler.mem_read_bw[1] = memory[\"frequency\"]*memory[\"banks\"]*memory[\"read_ports\"]*memory[\"width\"]\n",
    "#         scheduler.config[\"memory\"][\"level0\"][\"size\"]=10**(i/2)\n",
    "#         scheduler.mem_size[0] = 10**(i/2)\n",
    "#         print(scheduler.mem_read_bw[1], scheduler.mem_size[0])\n",
    "#         print(\"Config i : \",i , \", j :\", j)\n",
    "#         design_runner([dlrm_graph], scheduler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Connectivity Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax2 = ax.twinx()\n",
    "# base_dir = \"figures/\"\n",
    "# error_config = {\"ecolor\": \"0.3\"}\n",
    "# index = np.arange(6)\n",
    "# j=0\n",
    "# scheduler.config[\"memory\"][\"level1\"][\"frequency\"]=5\n",
    "# scheduler.config[\"memory\"][\"level1\"][\"frequency\"]*=2**j\n",
    "# time_list, bandwidth_time_list,_,bank_list,_,_,_= runner_save_all([vgg11_graph],scheduler)\n",
    "# plot_time_descent_multiple(ax, time_list, bandwidth_time_list, time_list_label=\"Execution time\")\n",
    "# plot_parameter_change_multiple(ax2, bank_list)\n",
    "# TODO Check this out something really weird going on with DLRM's \n",
    "# for j in range(0,5):\n",
    "#     scheduler = Scheduling()\n",
    "#     scheduler.config[\"memory\"][\"level1\"][\"frequency\"]=5\n",
    "#     scheduler.config[\"memory\"][\"level1\"][\"frequency\"]*=2**j\n",
    "#     memory = scheduler.config[\"memory\"][\"level1\"]\n",
    "#     scheduler.mem_read_bw[1] = memory[\"frequency\"]*memory[\"banks\"]*memory[\"read_ports\"]*memory[\"width\"]\n",
    "#     time_list, bandwidth_time_list,_,bank_list,_,_,_= runner_save_all([vgg11_graph],scheduler)\n",
    "#     plot_time_descent_multiple(ax, time_list, bandwidth_time_list)\n",
    "#     plot_parameter_change_multiple(ax2, bank_list)\n",
    "# ax.legend(fontsize=20)\n",
    "# ax.set_xticks(index)\n",
    "# plt.xticks(rotation=80)\n",
    "# plt.rc(\"xtick\", labelsize=20)  # fontsize of the tick labels\n",
    "# plt.rc(\"ytick\", labelsize=20)\n",
    "# ax.set_ylabel(\"Execution time\", fontsize=20, fontweight=\"bold\")\n",
    "# ax2.set_ylabel(\"External Memory Connectivity\", fontsize=20, fontweight=\"bold\")\n",
    "# ax.set_xlabel(\"Number of Iterations\", fontsize=20, fontweight=\"bold\")\n",
    "# ax2.set_ylabel(\"\")\n",
    "# fig.tight_layout()\n",
    "# plt.yscale(\"log\")\n",
    "# plt.savefig(base_dir + \"multiple_bandwidth.png\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Sweep Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax2 = ax.twinx()\n",
    "# base_dir = \"figures/\"\n",
    "# error_config = {\"ecolor\": \"0.3\"}\n",
    "# index = np.arange(6)\n",
    "# scheduler = Scheduling()\n",
    "# i=5\n",
    "# scheduler.config[\"memory\"][\"level0\"][\"size\"]=10**(i/2)\n",
    "# time_list, bandwidth_time_list,mem_size_idle_time_list, bank_list, mem_size_list, compute_list,_ = runner_save_all([bert_graph_data],scheduler)\n",
    "# plot_time_descent_multiple(ax, time_list, mem_size_idle_time_list, time_list_label=\"Execution time\", descent_list_label=\"Gradient Descent\")\n",
    "# plot_parameter_change_multiple(ax2, mem_size_list, parameter_label = \"Global Memory Size\")\n",
    "# for i in range(6,10):\n",
    "#     scheduler = Scheduling()\n",
    "#     scheduler.config[\"memory\"][\"level0\"][\"size\"]=10**(i/2)\n",
    "#     time_list, bandwidth_time_list,mem_size_idle_time_list, bank_list, mem_size_list, compute_list,_ = runner_save_all([bert_graph_data],scheduler)\n",
    "#     plot_time_descent_multiple(ax, time_list, mem_size_idle_time_list)\n",
    "#     plot_parameter_change_multiple(ax2, mem_size_list)\n",
    "# ax.legend(fontsize=20)\n",
    "# ax.set_xticks(index)\n",
    "# plt.xticks(rotation=80)\n",
    "# plt.rc(\"xtick\", labelsize=20)  # fontsize of the tick labels\n",
    "# plt.rc(\"ytick\", labelsize=20)\n",
    "# ax.set_ylabel(\"Total Execution time\", fontsize=20, fontweight=\"bold\")\n",
    "# ax2.set_ylabel(\"Global Memory Size\", fontsize=20, fontweight=\"bold\")\n",
    "# ax.set_xlabel(\"Number of Iterations\", fontsize=20, fontweight=\"bold\")\n",
    "# fig.tight_layout()\n",
    "# plt.yscale(\"log\")\n",
    "# plt.savefig(base_dir + \"memory_size_multiple.png\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technology Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "d = pd.read_csv('tables/sram.csv')\n",
    "a = np.array(d)\n",
    "\n",
    "input = a[:,:3]\n",
    "# output = a[:,3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('plugins/cacti/bus_width.out')\n",
    "\n",
    "\n",
    "d = d.drop(d.columns[[0,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]], axis=1)\n",
    "\n",
    "d = d.drop(' Associativity',1)\n",
    "d = d.drop(' Dynamic search energy (nJ)',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array(d)\n",
    "np.savetxt('bus.csv',a, fmt='%.18e', delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_graph(\"read_dummy.png\", read_bw_req, read_bw_actual, read_bw_limit, graph.nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_table = np.array(pd.read_csv(\"tables/sram.csv\", header=None))\n",
    "a = mem_table[np.where(mem_table[:, 1] == 4)]\n",
    "a = a[np.where(a[:, 2] == 32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute:\n",
    "    name       : MACs\n",
    "        class      : mac\n",
    "        attributes :            \n",
    "        instances       : 256\n",
    "        meshX           : 16\n",
    "        word-bits       : 16\n",
    "\n",
    "    memory: \n",
    "        name       : DRAM\n",
    "        class      : DRAM\n",
    "        attributes :\n",
    "        instances       : 1\n",
    "        word-bits       : 16\n",
    "  \n",
    "    name       : OutputBuffer\n",
    "        class      : SRAM\n",
    "        attributes :\n",
    "        entries         : 1024  # 64 * 16 = 1024\n",
    "        instances       : 1\n",
    "        meshX           : 1\n",
    "        word-bits       : 16\n",
    "        block-size      : 16\n",
    "        read_bandwidth  : 16 # words/cycle\n",
    "        write_bandwidth : 16 # words/cycle\n",
    "\n",
    "        name       : InputBuffer\n",
    "            class      : SRAM\n",
    "            attributes :\n",
    "            entries         : 1024 # 64 * 16 = 1024\n",
    "            instances       : 1\n",
    "            meshX           : 1\n",
    "            word-bits       : 16\n",
    "            block-size      : 16\n",
    "            read_bandwidth  : 16 # words/cycle\n",
    "            write_bandwidth : 16 # words/cycle\n",
    "\n",
    "        name       : PsumRegFile\n",
    "            class      : regfile\n",
    "            attributes :\n",
    "            entries         : 1\n",
    "            instances       : 16\n",
    "            meshX           : 16\n",
    "            word-bits       : 16\n",
    "            cluster-size    : 16\n",
    "            read_bandwidth  : 1  # words/cycle\n",
    "            write_bandwidth : 1  # words/cycle\n",
    "            \n",
    "        name       : WeightBuffer\n",
    "            class      : regfile\n",
    "            attributes :\n",
    "            entries         : 64\n",
    "            instances       : 256\n",
    "            meshX           : 16\n",
    "            word-bits       : 16\n",
    "            cluster-size    : 256\n",
    "            read_bandwidth  : 1  # words/cycle\n",
    "            write_bandwidth : 1  # words/cycle\n",
    "    noc:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_rep = make_graph_from_trace()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stanford_code]",
   "language": "python",
   "name": "conda-env-stanford_code-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
