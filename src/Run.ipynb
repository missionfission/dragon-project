{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import yamlordereddictloader\n",
    "\n",
    "from torchvision import models\n",
    "from yaml import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scheduling import Scheduling\n",
    "from generator import Generator, get_mem_props\n",
    "from generator import *\n",
    "from utils.visualizer import *\n",
    "from ir.trace import trace\n",
    "from main import design_tech_runner, design_runner, run_single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common_models import vggnet_graph, resnet_graph, bert_graph, gpt2_graph, dlrm_graph, alexnet_graph\n",
    "# design_runner([vggnet_graph()])\n",
    "# # for node in dlrm_graph.nodes:\n",
    "# #     print(node.in_edge_mem + node.mem_fetch + node.out_edge_mem, node.compute_expense )\n",
    "\n",
    "# design_tech_runner([dlrm_graph])\n",
    "vgg11_graph = vggnet_graph()\n",
    "resnet_graph_data = resnet_graph()\n",
    "# dlrm_graph_data = dlrm_graph()\n",
    "bert_graph_data = bert_graph()\n",
    "gpt2_graph_data = gpt2_graph()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# import torch\n",
    "\n",
    "# for name, model in models.__dict__.items():\n",
    "# #             print(name)\n",
    "#         if not name.islower() or name.startswith(\"__\") or not callable(model):\n",
    "#         #             print(name.islower())\n",
    "#             continue\n",
    "# #         print(name)\n",
    "#         if \"alexnet\" in name:\n",
    "#             model = model().eval()\n",
    "#             inputs = torch.randn(1, 3, 224, 224)\n",
    "#             alexnet_graph = trace(model, inputs)\n",
    "#             break\n",
    "#     return resnet_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_illusion_sim(vgg11_graph, False)\n",
    "# run_illusion_sim(resnet_graph_data, False)\n",
    "# run_illusion_sim(bert_graph_data, False)\n",
    "# run_illusion_sim(dlrm_graph_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from gnn_model import gnn_graph\n",
    "# from gan_model import gan_graph\n",
    "# from dart_model import dart_graph\n",
    "# from a3c_model import a3c_graph\n",
    "# design_tech_runner([gnn_graph])\n",
    "# design_tech_runner([dart_graph()])\n",
    "# design_tech_runner([a3c_graph()]) # Actor Critic\n",
    "\n",
    "# gan_graph in inference netG\n",
    "# design_tech_runner([gan_graph()])\n",
    "\n",
    "# # gan_graph in training netD(training)*2 + netG(inference) + (netG+netD)-> training \n",
    "# graph1, graph2 = gan_graph(True)\n",
    "# design_tech_runner([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vgg11_graph = vggnet_graph()\n",
    "# dlrm_graph_data = dlrm_graph()\n",
    "# bert_graph_data = bert_graph()\n",
    "# gpt2_graph_data = gpt2_graph()\n",
    "# resnet_graph_data = resnet_graph()\n",
    "# Does memory read energy doubles up on increasing the array size?\n",
    "# backprop = False\n",
    "\n",
    "# graph = dlrm_graph_data\n",
    "# in_time, in_energy, area = run_single(graph, backprop, False, \"tpu.yaml\")\n",
    "# arch_time, arch_energy, arch_area = design_runner([graph], backprop, print_stats= False)\n",
    "# scale_energy = np.sum(arch_energy[1:5])*area/arch_area+np.sum(arch_energy[5:])\n",
    "# print(in_time[0]/arch_time[0]*area/arch_area, (in_energy[0])/scale_energy )\n",
    "# print(in_time[0]/arch_time[0], (in_energy[0])/arch_energy[0], area/arch_area )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # dlrm_graph_data = dlrm_graph()\n",
    "# # resnet_graph_data = resnet_graph()\n",
    "# # Does memory read energy doubles up on increasing the array size?\n",
    "\n",
    "# backprop = False\n",
    "# name = [\"vgg_graph\", \"resnet_graph\",\"bert_graph\",\"gpt2_graph\", \"dlrm_graph\"]\n",
    "# graph_list = [vgg11_graph, resnet_graph_data, bert_graph_data, gpt2_graph_data, dlrm_graph_data]\n",
    "# # graph_list = []\n",
    "# # name = [\"dlrm_graph\"]\n",
    "\n",
    "# for i,graph in enumerate(graph_list):\n",
    "# # for graph in [bert_graph_data]:\n",
    "#     log_file_name = \"logs/\"+str(name[i])+str(backprop)\n",
    "#     arch_time, arch_energy, arch_area = design_runner([graph], backprop, print_stats= False, stats_file = log_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = False\n",
    "import time\n",
    "start = time.time()\n",
    "# name = [\"vgg_graph\", \"resnet_graph\",\"bert_graph\",\"gpt2_graph\", \"dlrm_graph\"]\n",
    "# graph_list = [vgg11_graph, resnet_graph_data, bert_graph_data, gpt2_graph_data, dlrm_graph_data]\n",
    "graph_list = [vgg11_graph]\n",
    "name = [\"vgg_graph\"]\n",
    "\n",
    "for i,graph in enumerate(graph_list):\n",
    "# for graph in [bert_graph_data]:\n",
    "    log_file_name = \"logs/\"+str(name[i])+str(backprop)\n",
    "    arch_time, arch_energy, arch_area = design_runner([graph], backprop, print_stats= False, stats_file = log_file_name)\n",
    "end = time.time()\n",
    "print(start-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = False\n",
    "log_file_name = \"logs/alexnet\"+str(backprop)\n",
    "design_runner([alexnet_graph()], backprop, print_stats= False, stats_file = log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for j in range(0,5):\n",
    "#     for i in range(5,15):\n",
    "#         scheduler = Scheduling()\n",
    "#         scheduler.config[\"memory\"][\"level1\"][\"frequency\"]=5\n",
    "#         scheduler.config[\"memory\"][\"level1\"][\"frequency\"]*=2**j\n",
    "#         memory = scheduler.config[\"memory\"][\"level1\"]\n",
    "#         scheduler.mem_read_bw[1] = memory[\"frequency\"]*memory[\"banks\"]*memory[\"read_ports\"]*memory[\"width\"]\n",
    "#         scheduler.config[\"memory\"][\"level0\"][\"size\"]=10**(i/2)\n",
    "#         scheduler.mem_size[0] = 10**(i/2)\n",
    "#         print(scheduler.mem_read_bw[1], scheduler.mem_size[0])\n",
    "#         print(\"Config i : \",i , \", j :\", j)\n",
    "#         design_runner([dlrm_graph], scheduler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technology Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "d = pd.read_csv('tables/sram.csv')\n",
    "a = np.array(d)\n",
    "\n",
    "# input = a[:,:3]\n",
    "# output = a[:,3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # d = pd.read_csv('plugins/cacti/bus_width.out')\n",
    "# d = pd.read_csv('plugins/cacti/cache.cfg.out')\n",
    "\n",
    "# d = d.drop(d.columns[[12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]], axis=1)\n",
    "\n",
    "# d = d.drop(' Associativity',1)\n",
    "# d = d.drop(' Dynamic search energy (nJ)',1)\n",
    "# d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array(d)\n",
    "np.savetxt('logic.csv',a, fmt='%.18e', delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_graph(\"read_dummy.png\", read_bw_req, read_bw_actual, read_bw_limit, graph.nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_table = np.array(pd.read_csv(\"tables/sram.csv\", header=None))\n",
    "a = mem_table[np.where(mem_table[:, 1] == 4)]\n",
    "a = a[np.where(a[:, 2] == 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_rep = make_graph_from_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "inputs = torch.randn(1,1,4,4)\n",
    "model = nn.Conv2d(1, 4, 3, 1, 1, bias=False)\n",
    "input_graph=trace(model, inputs)\n",
    "# design_tech_runner([input_graph], backprop=False,print_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze N3XT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "inputs = torch.randn(1,1,4,4)\n",
    "model = nn.Conv2d(1, 4, 3, 1, 0, bias=False)\n",
    "input_graph=trace(model, inputs)\n",
    "# design_tech_runner([input_graph], backprop=False,print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_single(input_graph, False, True, \"tsmc.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_single(input_graph, False, True, \"tsmc.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit ('dl': conda)",
   "language": "python",
   "name": "python36464bitdlconda74ce50dd77ab450dad146f0ee6a8041f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}