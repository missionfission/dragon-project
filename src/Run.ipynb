{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import yamlordereddictloader\n",
    "\n",
    "from torchvision import models\n",
    "from yaml import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scheduling import Scheduling\n",
    "from generator import Generator, get_mem_props\n",
    "from generator import *\n",
    "from utils.visualizer import *\n",
    "from ir.trace import trace\n",
    "from main import perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common_models import alexnet_graph, vggnet_graph, resnet_graph, bert_graph, gpt2_graph, dlrm_graph, alexnet_graph, langmodel_graph\n",
    "# design_runner([vggnet_graph()])\n",
    "# # for node in dlrm_graph.nodes:\n",
    "# #     print(node.in_edge_mem + node.mem_fetch + node.out_edge_mem, node.compute_expense )\n",
    "\n",
    "# design_tech_runner([dlrm_graph])\n",
    "vgg11_graph = vggnet_graph()\n",
    "resnet_graph_data = resnet_graph()\n",
    "alexnet_data = alexnet_graph()\n",
    "langmod_graph1, langmod_graph2 = langmodel_graph()\n",
    "# dlrm_graph_data = dlrm_graph()\n",
    "bert_graph_data = bert_graph()\n",
    "gpt2_graph_data = gpt2_graph()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(bert_graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# import torch\n",
    "\n",
    "# for name, model in models.__dict__.items():\n",
    "# #             print(name)\n",
    "#         if not name.islower() or name.startswith(\"__\") or not callable(model):\n",
    "#         #             print(name.islower())\n",
    "#             continue\n",
    "# #         print(name)\n",
    "#         if \"alexnet\" in name:\n",
    "#             model = model().eval()\n",
    "#             inputs = torch.randn(1, 3, 224, 224)\n",
    "#             alexnet_graph = trace(model, inputs)\n",
    "#             break\n",
    "#     return resnet_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from gnn_model import gnn_graph\n",
    "# from gan_model import gan_graph\n",
    "# from dart_model import dart_graph\n",
    "# from a3c_model import a3c_graph\n",
    "# design_tech_runner([gnn_graph])\n",
    "# design_tech_runner([dart_graph()])\n",
    "# design_tech_runner([a3c_graph()]) # Actor Critic\n",
    "\n",
    "# gan_graph in inference netG\n",
    "# design_tech_runner([gan_graph()])\n",
    "\n",
    "# # gan_graph in training netD(training)*2 + netG(inference) + (netG+netD)-> training \n",
    "# graph1, graph2 = gan_graph(True)\n",
    "# design_tech_runner([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vgg11_graph = vggnet_graph()\n",
    "# dlrm_graph_data = dlrm_graph()\n",
    "# bert_graph_data = bert_graph()\n",
    "# gpt2_graph_data = gpt2_graph()\n",
    "# resnet_graph_data = resnet_graph()\n",
    "# Does memory read energy doubles up on increasing the array size?\n",
    "# backprop = False\n",
    "\n",
    "# graph = dlrm_graph_data\n",
    "# in_time, in_energy, area = perf(graph, backprop, False, \"tpu.yaml\")\n",
    "# arch_time, arch_energy, arch_area = design_runner([graph], backprop, print_stats= False)\n",
    "# scale_energy = np.sum(arch_energy[1:5])*area/arch_area+np.sum(arch_energy[5:])\n",
    "# print(in_time[0]/arch_time[0]*area/arch_area, (in_energy[0])/scale_energy )\n",
    "# print(in_time[0]/arch_time[0], (in_energy[0])/arch_energy[0], area/arch_area )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # dlrm_graph_data = dlrm_graph()\n",
    "# # resnet_graph_data = resnet_graph()\n",
    "# # Does memory read energy doubles up on increasing the array size?\n",
    "\n",
    "# backprop = False\n",
    "# name = [\"vgg_graph\", \"resnet_graph\",\"bert_graph\",\"gpt2_graph\", \"dlrm_graph\"]\n",
    "# graph_list = [vgg11_graph, resnet_graph_data, bert_graph_data, gpt2_graph_data, dlrm_graph_data]\n",
    "# # graph_list = []\n",
    "# # name = [\"dlrm_graph\"]\n",
    "\n",
    "# for i,graph in enumerate(graph_list):\n",
    "# # for graph in [bert_graph_data]:\n",
    "#     log_file_name = \"logs/\"+str(name[i])+str(backprop)\n",
    "#     arch_time, arch_energy, arch_area = design_runner([graph], backprop, print_stats= False, stats_file = log_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = False\n",
    "import time\n",
    "start = time.time()\n",
    "# name = [\"vgg_graph\", \"resnet_graph\",\"bert_graph\",\"gpt2_graph\", \"dlrm_graph\"]\n",
    "# graph_list = [vgg11_graph, resnet_graph_data, bert_graph_data, gpt2_graph_data, dlrm_graph_data]\n",
    "graph_list = [vgg11_graph]\n",
    "name = [\"vgg_graph\"]\n",
    "\n",
    "# for i,graph in enumerate(graph_list):\n",
    "# # for graph in [bert_graph_data]:\n",
    "#     log_file_name = \"logs/\"+str(name[i])+str(backprop)\n",
    "#     arch_time, arch_energy, arch_area = design_runner([graph], backprop, print_stats= False, stats_file = log_file_name)\n",
    "# end = time.time()\n",
    "# print(start-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = False\n",
    "log_file_name = \"logs/alexnet\"+str(backprop)\n",
    "design_runner([alexnet_graph()], backprop, print_stats= False, stats_file = log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for j in range(0,5):\n",
    "#     for i in range(5,15):\n",
    "#         scheduler = Scheduling()\n",
    "#         scheduler.config[\"memory\"][\"level1\"][\"frequency\"]=5\n",
    "#         scheduler.config[\"memory\"][\"level1\"][\"frequency\"]*=2**j\n",
    "#         memory = scheduler.config[\"memory\"][\"level1\"]\n",
    "#         scheduler.mem_read_bw[1] = memory[\"frequency\"]*memory[\"banks\"]*memory[\"read_ports\"]*memory[\"width\"]\n",
    "#         scheduler.config[\"memory\"][\"level0\"][\"size\"]=10**(i/2)\n",
    "#         scheduler.mem_size[0] = 10**(i/2)\n",
    "#         print(scheduler.mem_read_bw[1], scheduler.mem_size[0])\n",
    "#         print(\"Config i : \",i , \", j :\", j)\n",
    "#         design_runner([dlrm_graph], scheduler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technology Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "d = pd.read_csv('tables/sram.csv')\n",
    "a = np.array(d)\n",
    "\n",
    "# input = a[:,:3]\n",
    "# output = a[:,3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # d = pd.read_csv('plugins/cacti/bus_width.out')\n",
    "# d = pd.read_csv('plugins/cacti/cache.cfg.out')\n",
    "\n",
    "# d = d.drop(d.columns[[12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]], axis=1)\n",
    "\n",
    "# d = d.drop(' Associativity',1)\n",
    "# d = d.drop(' Dynamic search energy (nJ)',1)\n",
    "# d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array(d)\n",
    "np.savetxt('logic.csv',a, fmt='%.18e', delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_graph(\"read_dummy.png\", read_bw_req, read_bw_actual, read_bw_limit, graph.nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_table = np.array(pd.read_csv(\"tables/sram.csv\", header=None))\n",
    "a = mem_table[np.where(mem_table[:, 1] == 4)]\n",
    "a = a[np.where(a[:, 2] == 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_rep = make_graph_from_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "inputs = torch.randn(1,1,4,4)\n",
    "model = nn.Conv2d(1, 4, 3, 1, 1, bias=False)\n",
    "input_graph=trace(model, inputs)\n",
    "# design_tech_runner([input_graph], backprop=False,print_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze N3XT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Time 203605 14930 14309\n",
      "Energy 1245967810 169623898 657069416 12513260 10720629 1610601 6357889 53323 1610601583\n",
      "Area 285631 50462 24499 210669\n",
      "memory accesses 120287432 120287432 61117096 512592\n",
      "rf access 357102944.0\n",
      "Design Params \n",
      " No. of PEs :  4096 \n",
      " Memory Level-1 Connectivity :  256 \n",
      " Memory Level-0 Size :  2000000 \n",
      " Memory Level-0 Read Energy :  0.104028\n",
      "Tech Params [1, 1, 40]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([203605.837890625, 14930, 14309, 0],\n",
       " [1245967810, 169623898, 12513260, 10720629, 1610601, 391149414, 3280588, 0],\n",
       " 285631.669568)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(alexnet_data, backprop=False, print_stats=True, filename = 'illusion_nvm.yaml', mapping=\"nn_dataflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Time 3525114 34067 1633346\n",
      "Energy 9830682202 1807171654 7000412303 29351888 25146979 27885033 13824682 1466040 27885033780\n",
      "Area 285631 50462 24499 210669\n",
      "memory accesses 282153736 282153736 132893864 14092752\n",
      "rf access 3804571904.0\n",
      "Design Params \n",
      " No. of PEs :  4096 \n",
      " Memory Level-1 Connectivity :  256 \n",
      " Memory Level-0 Size :  2000000 \n",
      " Memory Level-0 Read Energy :  0.104028\n",
      "Tech Params [1, 1, 40]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3525114.916015625, 34067, 1633346, 0],\n",
       " [9830682202,\n",
       "  1807171654,\n",
       "  29351888,\n",
       "  25146979,\n",
       "  27885033,\n",
       "  850520729,\n",
       "  90193612,\n",
       "  0],\n",
       " 285631.669568)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(vgg11_graph, backprop=False, print_stats=True, filename = 'illusion_nvm.yaml', mapping=\"nn_dataflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Time 1165254 6384 160534\n",
      "Energy 4989825294 971181747 3762051399 5521181 4730224 9217617 2653334 1200954 9217617868\n",
      "Area 285631 50462 24499 210669\n",
      "memory accesses 53073992 53073992 25505960 11544528\n",
      "rf access 2044593152.0\n",
      "Design Params \n",
      " No. of PEs :  4096 \n",
      " Memory Level-1 Connectivity :  256 \n",
      " Memory Level-0 Size :  2000000 \n",
      " Memory Level-0 Read Energy :  0.104028\n",
      "Tech Params [1, 1, 40]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1165254.541015625, 6384, 160534, 0],\n",
       " [4989825294, 971181747, 5521181, 4730224, 9217617, 163238144, 73884979, 0],\n",
       " 285631.669568)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(resnet_graph_data, backprop=False, print_stats=True, filename = 'illusion_nvm.yaml', mapping=\"nn_dataflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Time 5280729 5245436 18909\n",
      "Energy 16267244760 15938355 61740154 13969432 11968191 41772625 6981200 6817 41772625874\n",
      "Area 285631 50462 24499 210669\n",
      "memory accesses 134285312 134285312 67108864 65536\n",
      "rf access 33554432.0\n",
      "Design Params \n",
      " No. of PEs :  4096 \n",
      " Memory Level-1 Connectivity :  4 \n",
      " Memory Level-0 Size :  2000000 \n",
      " Memory Level-0 Read Energy :  0.104028\n",
      "Tech Params [1, 1, 40]\n",
      "==================================\n",
      "Time 659612 655440 2124\n",
      "Energy 2031927591 1992294 7717519 1746365 1496183 5217788 872650 213 5217788168\n",
      "Area 285631 50462 24499 210669\n",
      "memory accesses 16787456 16787456 8388608 2048\n",
      "rf access 4194304.0\n",
      "Design Params \n",
      " No. of PEs :  4096 \n",
      " Memory Level-1 Connectivity :  4 \n",
      " Memory Level-0 Size :  2000000 \n",
      " Memory Level-0 Read Energy :  0.104028\n",
      "Tech Params [1, 1, 40]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([659612.0, 655440, 2124, 0],\n",
       " [2031927591, 1992294, 1746365, 1496183, 5217788, 2013265920, 491520, 0],\n",
       " 285631.669568)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf(langmod_graph1, backprop=False, print_stats=True, filename = 'illusion.yaml', mapping=\"nn_dataflow\")\n",
    "perf(langmod_graph2, backprop=False, print_stats=True, filename = 'illusion.yaml', mapping=\"nn_dataflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "inputs = torch.randn(1,1,4,4)\n",
    "model = nn.Conv2d(1, 4, 3, 1, 0, bias=False)\n",
    "input_graph=trace(model, inputs)\n",
    "# design_tech_runner([input_graph], backprop=False,print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perf(input_graph, False, True, \"tsmc.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perf(input_graph, False, True, \"tsmc.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-AI Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_graph_processing_design_generation(input_graph, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "from ir.staticfg.staticfg import CFGBuilder\n",
    "cfg = CFGBuilder().build_from_file(\n",
    "    \"hpcg.py\",\n",
    "    \"nonai_models/hpcg.py\",\n",
    ")\n",
    "# cfg.build_visual(\"hpcg\", \"pdf\", show=False)\n",
    "# print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ast.Import object at 0x7f7256c4c3a0>\n",
      "<_ast.Import object at 0x7f7256c4c640>\n",
      "<_ast.Import object at 0x7f7256c4cf40>\n",
      "<_ast.FunctionDef object at 0x7f7256c4c9a0>\n",
      "<_ast.BinOp object at 0x7f7256c4c8e0>\n",
      "(100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2)\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256cb8070>\n",
      "<_ast.Call object at 0x7f7256d69040>\n",
      "np.array([200 * (x[1] - x[0] ** 2) * (-2 * x[0]) + 2 * (x[0] - 1), 200 * (x\n",
      "    [1] - x[0] ** 2)])\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256d69d30>\n",
      "<_ast.Call object at 0x7f7256d69550>\n",
      "np.array([[1200 * x[0] ** 2 - 400 * x[1] + 2, -400 * x[0]], [-400 * x[0], 200]]\n",
      "    )\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256dae640>\n",
      "<_ast.Constant object at 0x7f7256daeaf0>\n",
      "(0.0001)\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256dae370>\n",
      "<_ast.BoolOp object at 0x7f7256dae940>\n",
      "(wolfe(f, g, xk, alpha, pk) and abs(np.dot(g(xk + alpha * pk), pk)) <= c2 *\n",
      "    abs(np.dot(g(xk), pk)))\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256cb1040>\n",
      "<_ast.BoolOp object at 0x7f7256dd2190>\n",
      "(f(xk) + (1 - c) * alpha * np.dot(g(xk), pk) <= f(xk + alpha * pk) and f(xk +\n",
      "    alpha * pk) <= f(xk) + c * alpha * np.dot(g(xk), pk))\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256dd2430>\n",
      "<_ast.Call object at 0x7f7256cc4640>\n",
      "interpolation(f, g, lambda alpha: f(xk + alpha * pk), lambda alpha: np.dot(\n",
      "    g(xk + alpha * pk), pk), alpha, c2, lambda f, g, alpha, c2:\n",
      "    strong_wolfe(f, g, xk, alpha, pk, c2))\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256d7ac10>\n",
      "<_ast.Constant object at 0x7f7256d7a790>\n",
      "(0.0)\n",
      "\n",
      "<_ast.FunctionDef object at 0x7f7256d32730>\n",
      "<_ast.Name object at 0x7f7256d322e0>\n",
      "<_ast.If object at 0x7f7256ddf250>\n",
      "(__name__ == '__main__')\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf7f0>\n",
      "x0 = np.array([0, 0])\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf610>\n",
      "error = 0.0001\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf8b0>\n",
      "max_iterations = 1000\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf070>\n",
      "start = time.time()\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddfe80>\n",
      "x, n_iter = conjugate_gradient(rosenbrock, grad_rosen, x0, iterations=\n",
      "    max_iterations, error=error)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf9a0>\n",
      "end = time.time()\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Return object at 0x7f7256c4cd60>\n",
      "(100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2)\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Return object at 0x7f7256cb8dc0>\n",
      "np.array([200 * (x[1] - x[0] ** 2) * (-2 * x[0]) + 2 * (x[0] - 1), 200 * (x\n",
      "    [1] - x[0] ** 2)])\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Return object at 0x7f7256d69bb0>\n",
      "np.array([[1200 * x[0] ** 2 - 400 * x[1] + 2, -400 * x[0]], [-400 * x[0], 200]]\n",
      "    )\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Assign object at 0x7f7256daeca0>\n",
      "c1 = 0.0001\n",
      "\n",
      "<_ast.Return object at 0x7f7256dae9a0>\n",
      "(f(xk + alpha * pk) <= f(xk) + c1 * alpha * np.dot(g(xk), pk))\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Return object at 0x7f7256dae850>\n",
      "(wolfe(f, g, xk, alpha, pk) and abs(np.dot(g(xk + alpha * pk), pk)) <= c2 *\n",
      "    abs(np.dot(g(xk), pk)))\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Return object at 0x7f7256dd2250>\n",
      "(f(xk) + (1 - c) * alpha * np.dot(g(xk), pk) <= f(xk + alpha * pk) and f(xk +\n",
      "    alpha * pk) <= f(xk) + c * alpha * np.dot(g(xk), pk))\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Return object at 0x7f7256cc4700>\n",
      "interpolation(f, g, lambda alpha: f(xk + alpha * pk), lambda alpha: np.dot(\n",
      "    g(xk + alpha * pk), pk), alpha, c2, lambda f, g, alpha, c2:\n",
      "    strong_wolfe(f, g, xk, alpha, pk, c2))\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Assign object at 0x7f7256d7afa0>\n",
      "l = 0.0\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d7a1c0>\n",
      "h = 1.0\n",
      "\n",
      "<_ast.For object at 0x7f7256d7ab80>\n",
      "printing Loop\n",
      "for i in range(iters):\n",
      "    if strong_wolfe_alpha(f, g, alpha, c2):\n",
      "        return alpha\n",
      "    half = (l + h) / 2\n",
      "    alpha = -g_alpha(l) * h ** 2 / (2 * (f_alpha(h) - f_alpha(l) - g_alpha(\n",
      "        l) * h))\n",
      "    if alpha < l or alpha > h:\n",
      "        alpha = half\n",
      "    if g_alpha(alpha) > 0:\n",
      "        h = alpha\n",
      "    elif g_alpha(alpha) <= 0:\n",
      "        l = alpha\n",
      "\n",
      "<_ast.If object at 0x7f7256d7a7f0>\n",
      "strong_wolfe_alpha(f, g, alpha, c2)\n",
      "\n",
      "<_ast.Return object at 0x7f7256d32790>\n",
      "alpha\n",
      "\n",
      "<_ast.Return object at 0x7f7256d7a2b0>\n",
      "alpha\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d7a280>\n",
      "half = (l + h) / 2\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d7a340>\n",
      "alpha = -g_alpha(l) * h ** 2 / (2 * (f_alpha(h) - f_alpha(l) - g_alpha(l) * h))\n",
      "\n",
      "<_ast.If object at 0x7f7256c30cd0>\n",
      "alpha < l or alpha > h\n",
      "\n",
      "<_ast.Assign object at 0x7f7256c300d0>\n",
      "alpha = half\n",
      "\n",
      "<_ast.If object at 0x7f7256c307c0>\n",
      "g_alpha(alpha) > 0\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d32490>\n",
      "h = alpha\n",
      "\n",
      "<_ast.If object at 0x7f7256d32cd0>\n",
      "g_alpha(alpha) <= 0\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d328e0>\n",
      "l = alpha\n",
      "\n",
      "Yield from Subgraphs\n",
      "<_ast.Assign object at 0x7f7256d327f0>\n",
      "xk = x0\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d323a0>\n",
      "c2 = 0.1\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d326d0>\n",
      "fk = f(xk)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d328b0>\n",
      "gk = g(xk)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d32c70>\n",
      "pk = -gk\n",
      "\n",
      "<_ast.For object at 0x7f7256d32b80>\n",
      "printing Loop\n",
      "for i in range(iterations):\n",
      "    alpha = step_length(f, g, xk, 1.0, pk, c2)\n",
      "    xk1 = xk + alpha * pk\n",
      "    gk1 = g(xk1)\n",
      "    beta_k1 = np.dot(gk1, gk1) / np.dot(gk, gk)\n",
      "    pk1 = -gk1 + beta_k1 * pk\n",
      "    if np.linalg.norm(xk1 - xk) < error:\n",
      "        xk = xk1\n",
      "        break\n",
      "    xk = xk1\n",
      "    gk = gk1\n",
      "    pk = pk1\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d32370>\n",
      "alpha = step_length(f, g, xk, 1.0, pk, c2)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d32700>\n",
      "xk1 = xk + alpha * pk\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d32340>\n",
      "gk1 = g(xk1)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256d32610>\n",
      "beta_k1 = np.dot(gk1, gk1) / np.dot(gk, gk)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256c049a0>\n",
      "pk1 = -gk1 + beta_k1 * pk\n",
      "\n",
      "<_ast.If object at 0x7f7256ddf640>\n",
      "np.linalg.norm(xk1 - xk) < error\n",
      "\n",
      "<_ast.Return object at 0x7f7256ddfee0>\n",
      "(xk, i + 1)\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf490>\n",
      "xk = xk1\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf760>\n",
      "xk = xk1\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddff40>\n",
      "gk = gk1\n",
      "\n",
      "<_ast.Assign object at 0x7f7256ddf580>\n",
      "pk = pk1\n",
      "\n",
      "Yield from Subgraphs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_source(filename):\n",
    "    assert filename\n",
    "    f = open(filename, 'r')\n",
    "    source_lines = f.readlines()\n",
    "    f.close()\n",
    "    src_texts[filename] = source_lines\n",
    "    source = ''.join(source_lines)\n",
    "    return source\n",
    "\n",
    "\n",
    "def get_src_text(filename, lineno):\n",
    "    assert lineno > 0\n",
    "    return src_texts[filename][lineno - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "std::string ConsecutiveBranchFusion::getCenteredName(size_t size) {\n",
    "  return \"   Fuse consecutive branches   \";\n",
    "}\n",
    "\n",
    "void ConsecutiveBranchFusion::optimize() {\n",
    "  std::set<Edge> to_remove_edges;\n",
    "  std::vector<NewEdge> to_add_edges;\n",
    "\n",
    "  std::list<Vertex> topo_nodes;\n",
    "  boost::topological_sort(graph, std::front_inserter(topo_nodes));\n",
    "\n",
    "  for (auto vi = topo_nodes.begin(); vi != topo_nodes.end(); ++vi) {\n",
    "    Vertex vertex = *vi;\n",
    "    ExecNode* node = getNodeFromVertex(vertex);\n",
    "    if (!(node->is_branch_op() || node->is_call_op()))\n",
    "      continue;\n",
    "    if (boost::out_degree(vertex, graph) != 1)\n",
    "      continue;\n",
    "\n",
    "    std::list<ExecNode*> branch_chain{ node };\n",
    "    findBranchChain(node, branch_chain, to_remove_edges);\n",
    "    if (branch_chain.size() > 1) {\n",
    "      for (auto it = branch_chain.begin(); it != --branch_chain.end();)\n",
    "        to_add_edges.push_back({ *it, *(++it), FUSED_BRANCH_EDGE });\n",
    "    }\n",
    "  }\n",
    "\n",
    "  updateGraphWithIsolatedEdges(to_remove_edges);\n",
    "  updateGraphWithNewEdges(to_add_edges);\n",
    "  cleanLeafNodes();\n",
    "}\n",
    "\n",
    "void ConsecutiveBranchFusion::findBranchChain(\n",
    "    ExecNode* root,\n",
    "    std::list<ExecNode*>& branch_chain,\n",
    "    std::set<Edge>& to_remove_edges) {\n",
    "\n",
    "  if (boost::out_degree(root->get_vertex(), graph) != 1)\n",
    "    return;\n",
    "  out_edge_iter out_edge_it, out_edge_end;\n",
    "  for (boost::tie(out_edge_it, out_edge_end) =\n",
    "           out_edges(root->get_vertex(), graph);\n",
    "       out_edge_it != out_edge_end;\n",
    "       ++out_edge_it) {\n",
    "    Vertex target_vertex = target(*out_edge_it, graph);\n",
    "    ExecNode* target_node = getNodeFromVertex(target_vertex);\n",
    "    if (target_node->is_branch_op() || target_node->is_call_op()) {\n",
    "      branch_chain.push_back(target_node);\n",
    "      to_remove_edges.insert(*out_edge_it);\n",
    "      findBranchChain(target_node, branch_chain, to_remove_edges);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stanford_code]",
   "language": "python",
   "name": "conda-env-stanford_code-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
