<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>nonai_schedule API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>nonai_schedule</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import ast
import re

import astor

from generator import get_mem_props
from ir.cfg.staticfg import CFGBuilder

lib_hw_dict = [&#34;add&#34;, &#34;mult&#34;, &#34;buffer&#34;, &#34;reg&#34;, &#34;sys_array&#34;, &#34;logic&#34;, &#34;fsm&#34;]
common_ops = set()
op2sym_map = {
    &#34;And&#34;: &#34;and&#34;,
    &#34;Or&#34;: &#34;or&#34;,
    &#34;Add&#34;: &#34;+&#34;,
    &#34;Sub&#34;: &#34;-&#34;,
    &#34;Mult&#34;: &#34;*&#34;,
    &#34;FloorDiv&#34;: &#34;//&#34;,
    &#34;Mod&#34;: &#34;%&#34;,
    &#34;LShift&#34;: &#34;&lt;&lt;&#34;,
    &#34;RShift&#34;: &#34;&gt;&gt;&#34;,
    &#34;BitOr&#34;: &#34;|&#34;,
    &#34;BitXor&#34;: &#34;^&#34;,
    &#34;BitAnd&#34;: &#34;&amp;&#34;,
    &#34;Eq&#34;: &#34;==&#34;,
    &#34;NotEq&#34;: &#34;!=&#34;,
    &#34;Lt&#34;: &#34;&lt;&#34;,
    &#34;LtE&#34;: &#34;&lt;=&#34;,
    &#34;Gt&#34;: &#34;&gt;&#34;,
    &#34;GtE&#34;: &#34;&gt;=&#34;,
    &#34;IsNot&#34;: &#34;!=&#34;,
    &#34;USub&#34;: &#34;-&#34;,
    &#34;UAdd&#34;: &#34;+&#34;,
    &#34;Not&#34;: &#34;!&#34;,
    &#34;Invert&#34;: &#34;~&#34;,
}
delimiters = (
    &#34;+&#34;,
    &#34;-&#34;,
    &#34;*&#34;,
    &#34;//&#34;,
    &#34;%&#34;,
    &#34;=&#34;,
    &#34;&gt;&gt;&#34;,
    &#34;&lt;&lt;&#34;,
    &#34;&lt;&#34;,
    &#34;&lt;=&#34;,
    &#34;&gt;&#34;,
    &#34;&gt;=&#34;,
    &#34;!=&#34;,
    &#34;~&#34;,
    &#34;!&#34;,
    &#34;^&#34;,
    &#34;&amp;&#34;,
)
regexPattern = &#34;|&#34;.join(map(re.escape, delimiters))

latency = {
    &#34;And&#34;: 1,
    &#34;Or&#34;: 1,
    &#34;Add&#34;: 4,
    &#34;Sub&#34;: 4,
    &#34;Mult&#34;: 5,
    &#34;FloorDiv&#34;: 16,
    &#34;Mod&#34;: 3,
    &#34;LShift&#34;: 0.70,
    &#34;RShift&#34;: 0.70,
    &#34;BitOr&#34;: 0.06,
    &#34;BitXor&#34;: 0.06,
    &#34;BitAnd&#34;: 0.06,
    &#34;Eq&#34;: 1,
    &#34;NotEq&#34;: 1,
    &#34;Lt&#34;: 1,
    &#34;LtE&#34;: 1,
    &#34;Gt&#34;: 1,
    &#34;GtE&#34;: 1,
    &#34;USub&#34;: 0.42,
    &#34;UAdd&#34;: 0.42,
    &#34;IsNot&#34;: 1,
    &#34;Not&#34;: 0.06,
    &#34;Invert&#34;: 0.06,
    &#34;Regs&#34;: 1,
}
energy = {}
power = {
    &#34;And&#34;: 32 * [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;Or&#34;: 32 * [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;Add&#34;: [2.537098e00, 3.022642e00, 5.559602e00, 1.667880e01, 5.311069e-02],
    &#34;Sub&#34;: [2.537098e00, 3.022642e00, 5.559602e00, 1.667880e01, 5.311069e-02],
    &#34;Mult&#34;: [5.050183e00, 6.723213e00, 1.177340e01, 3.532019e01, 1.198412e-01],
    &#34;FloorDiv&#34;: [5.050183e00, 6.723213e00, 1.177340e01, 3.532019e01, 1.198412e-01],
    &#34;Mod&#34;: [5.050183e00, 6.723213e00, 1.177340e01, 3.532019e01, 1.198412e-01],
    &#34;LShift&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;RShift&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;BitOr&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;BitXor&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;BitAnd&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;Eq&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;NotEq&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;Lt&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;LtE&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;Gt&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;GtE&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;USub&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;UAdd&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;IsNot&#34;: [8.162355e-02, 3.356332e-01, 4.172512e-01, 4.172512e-01, 1.697876e-03],
    &#34;Not&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;Invert&#34;: [1.010606e-02, 7.950398e-03, 1.805590e-02, 1.805590e-02, 6.111633e-04],
    &#34;Regs&#34;: [7.936518e-03, 1.062977e-03, 8.999495e-03, 8.999495e-03, 7.395312e-05],
}

hw_allocated = {}
memory_cfgs = {}
hw_utilized = {}

cycles = 0
hw_allocated[&#34;Regs&#34;] = 0
hw_utilized[&#34;Regs&#34;] = 0


def schedule(expr, type):
    &#34;&#34;&#34;[Schedules the expr from AST]

    Args:
        expr (): 
        type (): 

    Returns:
        : 
    &#34;&#34;&#34;
    # rescheduleNodesWhenNeeded : (ALAP) rescheduling for non-memory, non-control nodes.
    # upsamplelloops
    # run
    hw_need = {}
    num_cycles = 0
    for key in op2sym_map.keys():
        hw_need[key] = 0
    strs = re.split(regexPattern, expr)
    print(strs, expr)
    if strs.count(&#34;&#34;) &gt; 0:
        strs.remove(&#34;&#34;)
    num_vars = len(strs)
    for i, op in enumerate(op2sym_map.values()):
        hw_need[list(op2sym_map.keys())[i]] += expr.count(op)
        num_cycles += latency[list(op2sym_map.keys())[i]]  # ALAP
    hw_need[&#34;Regs&#34;] = num_vars
    return num_cycles, hw_need


def parse_code(expr, type, unrolled=1, loop_iters=1):
    &#34;&#34;&#34;[Parse the input Python Code file]

    Args:
        expr (): 
        type (): 
        unrolled (int, optional): . Defaults to 1.
        loop_iters (int, optional): . Defaults to 1.
    &#34;&#34;&#34;
    if type in [&#34;assign&#34;, &#34;expr&#34;, &#34;binop_nested&#34;, &#34;constant&#34;]:
        expr_cycles, hw_need = schedule(expr, type)
        global cycles, hw_allocated, hw_utilized
        cycles += expr_cycles * loop_iters / unrolled
        # hw_allocated = max(hw_need*unrolled, hw_allocated)
        hw_allocated = {
            key: max(value, hw_need[key] * unrolled)
            for key, value in hw_allocated.items()
        }
        hw_utilized = {
            key: value + hw_need[key] * unrolled for key, value in hw_utilized.items()
        }
        print(cycles)
    # if(type == &#34;assign&#34;):
    #     left, right = expr.split(&#34;=&#34;)
    #     parse_code(left, &#34;expr&#34;)
    #     parse_code(right, &#34;expr&#34;)
    # if(type == &#34;expr&#34;):
    #     for i,op in enumerate(op2sym_map.values()):
    #         hw_allocated[list(op2sym_map.keys())[i]] += expr.count(op)
    #     # expression is list operation such as append
    #     # expr.split(&#34; &#34;)
    #     # find brackets, create data path
    # if(type == &#34;binop_nested&#34;):
    #     for i,op in enumerate(op2sym_map.values()):
    #         hw_allocated[list(op2sym_map.keys())[i]] += expr.count(op)
    # if (type == &#34;binop_simple&#34;):
    #     for i,op in enumerate(op2sym_map.values()):
    #         hw_allocated[list(op2sym_map.keys())[i]] += expr.count(op)
    # if (type == &#34;constant&#34;):
    #     for i,op in enumerate(op2sym_map.values()):
    #         hw_allocated[list(op2sym_map.keys())[i]] += expr.count(op)


def check_and_parse(string, unrolled=1, loop_iters=1):
    &#34;&#34;&#34;

    Args:
        string (): 
        unrolled (int, optional): . Defaults to 1.
        loop_iters (int, optional): . Defaults to 1.
    &#34;&#34;&#34;
    if type(string) == ast.BinOp or ast.BoolOp:
        parse_code(astor.to_source(string), &#34;binop_nested&#34;, unrolled)
    if type(string) == ast.Call:
        # cycles += visit(string)
        # latency calculation of traversal
        pass
    if type(string) == ast.Constant:
        parse_code(astor.to_source(string), &#34;constant&#34;, unrolled)


def parse_graph(graph):
    &#34;&#34;&#34;
    Parse a non-AI workload graph and store the configuration as a hardware representation 
    &#34;&#34;&#34;
    for key in op2sym_map.keys():
        hw_allocated[key] = 0
        hw_utilized[key] = 0
    unroll_params = {}
    variables = {}
    global memory_cfgs

    # if node.operator in lib_common_ops:
    #     common_ops.add(node.operator)
    for node in graph:
        # yield(node)
        for i in node.statements:
            print(i)
            if type(i) == ast.Import:
                continue
            if type(i) == ast.FunctionDef:
                for string in i.body:
                    if isinstance(string, ast.For):
                        continue
                    # print(string)
                    check_and_parse(string)
            if type(i) == ast.Assign:
                # allocated memory/registers
                flag = True
                if isinstance(i.value, ast.Tuple):
                    for x in list(i.value.elts):
                        if not isinstance(x, ast.Constant):
                            flag = False
                    if flag:
                        if isinstance(i.targets[0], ast.Name):
                            variables[i.targets[0].id] = len(list(i.value.elts))
                else:
                    parse_code(astor.to_source(i), &#34;assign&#34;)
            if type(i) == ast.AugAssign:
                # allocated memory/registers
                parse_code(astor.to_source(i), &#34;assign&#34;)
            if type(i) == ast.Expr:
                parse_code(astor.to_source(i), &#34;expr&#34;)
            if type(i) == ast.If:
                check_and_parse(i.test)
            if type(i) == ast.Return:
                check_and_parse(i.value)
            if isinstance(i, ast.For):
                unrolled = 1
                print(ast.dump(i))
                if isinstance(i.iter.args[0], ast.Constant):
                    loop_iters = [i.iter.args[0].value]
                else:
                    print(&#34;Loop iters not captured&#34;)
                    loop_iters = 1
                print(&#34;Loop Iters are&#34;, loop_iters)
                print(&#34;Unrolled are&#34;, unrolled)
                for string in i.body:
                    check_and_parse(string, unrolled)
                # print(ast.dump(i))
                # transform
            # numpy library spmv, dot, conv
    memory_cfgs = variables
    # mem_list =  allocate_memory_cfgs()


def get_params(dfg, area_budget):
    &#34;&#34;&#34;

    Args:
        dfg (): 
        area_budget (): 
    &#34;&#34;&#34;
    allocated_area = 0
    while allocated_area &lt; 0.9 * area or allocated_area &gt; 1.2 * area:
        # unroll_params -&gt; modify
        # memory size -&gt; modify
        if area &gt; allocated_area:
            for param in unroll_params:
                # decrease parallelism
                # unroll_params --
                pass
            for mem_cfgs in memory_cfgs:
                # high registers to sram
                # decreases bandwidth
                # update_memory_cfgs
                pass
        # if(area &lt; allocated_area):
    pass


def allocate_memory_cfgs():
    &#34;&#34;&#34;[allocate_memory_cfgs]

    Returns:
        : 
    &#34;&#34;&#34;
    mem_list = {}
    for key, value in memory_cfgs.items():
        if value &gt; 32768:
            mem_list[key] = get_mem_props(value, 32, 1)
        else:
            mem_list[key] = power[&#34;Regs&#34;] * value
    return mem_list


def prune_allocator():

    # conflict graph
    # interval graph for registers
    if node.operator == &#34;func&#34;:
        getall = []
        for i in func:
            getall.append(allocate_node(i))
    return getall


# def get_fsm_overhead():
#       # fsm overhead and resource consumption
#     pass


# def create_datapath():
#     # cycle time
#     # functional units packing &lt; clock cycle
#     # datapath, scratchpad access and memory access
#     # call datapath optimizations
#     # step through memory accesses
#     # find common datapath of instances, or uncommon datapath -&gt; area constraint controlled
#     pass


# def optimizations():
#     pass
#     # initBaseAddress
#     # for each variable allocated assign a base address
#     # writeBaseAddress
#     # write base address to directory
#     # initDmaBaseAddress
#     # memoryAmbiguation
#     # removePhiNodes
#     # loopFlatten, loopUnrolling : Loop Tree
#     # removeInductionDependence
#     # GloballoopPipelining, perLoopPipelining
#     # fuseRegLoadStores, fuseConsecutiveBranches, removeSharedLoads : LoadBuffering
#     #  updateGraphWithIsolatedEdges(to_remove_edges);
#     #  updateGraphWithNewEdges(to_add_edges);
#     # storeBuffer, removeRepeatedStores, treeHeightReduction


# class graph_manipulations:
#     def __init__(self, graph):
#         self.graph = graph

#     def to_remove_edges(self):
#         pass

#     def to_add_edges(self):
#         pass

#     def isolated_nodes(self):
#         pass

#     def isolated_edges(self):
#         pass

#     def dependency_nodes(self):
#         pass


def get_stats(cfg):

    # Write logs
    # * cycle_num,num-of-muls,num-of-adds,num-of-bitwise-ops,num-of-reg-reads,num-of-reg-writes
    #  * If it is called from ScratchpadDatapath, it also outputs per cycle memory
    #  * activity for each partitioned array. add up all the activity of all the components to get the fina
    ddg = {}
    print(&#34;-------------------------------&#34;)
    print(&#34;Generating DDDG&#34;)
    avgpower = 0
    # print(&#34;Num of Nodes:&#34;,  ddg[&#39;nodes&#39;])
    # print(&#34;Num of Edges:&#34;,  ddg[&#39;edges&#39;])
    # print(&#34;Num of Reg Edges:&#34;, regedges)
    # print(&#34;Num of MEM Edges:&#34;, memedges)
    # print(&#34;Num of Control Edges:&#34;, controledges)
    print(&#34;Creating Base Data Path&#34;)
    print(&#34;Cycle :&#34;, cycles)
    print(&#34;Hardware &#34;)
    for keys in hw_utilized.keys():
        avgpower += power[keys][0] * hw_utilized[keys] * latency[keys] / cycles
    print(&#34;Avg Power :&#34;, avgpower)
    # print(&#34;Avg FU Power :&#34;, fupower)
    # print(&#34;Avg FU Dynamic Power:&#34;,fu_dynamic_power)
    # print(&#34;Avg FU leakage Power: &#34;, fu_leakage_power )
    # print(&#34;Avg MEM Power: &#34;, mempower)
    # print(&#34;Avg MEM Dynamic Power: &#34;, mem_dynamic_power)
    # print(&#34;Avg MEM Leakage Power: &#34;, mem_leakage_power)
    # print(&#34;Avg REG Power: &#34;, regpower)
    # print(&#34;Area Calculation :&#34;, area)
    print(hw_allocated, memory_cfgs)


## choices for scheduling :
## assumptions for our formulas : propagation of error


# lib_template_space = [&#34;global_mem&#34;, &#34;local_mem&#34;, &#34;pes&#34;, &#34;noc&#34;, &#34;buffers&#34;]


# def template_space(H):
#     template_space = {}
#     for i in lib_template_space:
#         template_space[i] = template_handlers(i, hw_allocated)


# def template_handlers(i, hw_allocated):
#     return hw_allocated.gather(i)


# def allocation(H):
#     for node in graph:
#         hw_allocated[node.name] = allocate(node)


#     return hw_allocated</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="nonai_schedule.allocate_memory_cfgs"><code class="name flex">
<span>def <span class="ident">allocate_memory_cfgs</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>[allocate_memory_cfgs]</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code></code></dt>
<dd></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def allocate_memory_cfgs():
    &#34;&#34;&#34;[allocate_memory_cfgs]

    Returns:
        : 
    &#34;&#34;&#34;
    mem_list = {}
    for key, value in memory_cfgs.items():
        if value &gt; 32768:
            mem_list[key] = get_mem_props(value, 32, 1)
        else:
            mem_list[key] = power[&#34;Regs&#34;] * value
    return mem_list</code></pre>
</details>
</dd>
<dt id="nonai_schedule.check_and_parse"><code class="name flex">
<span>def <span class="ident">check_and_parse</span></span>(<span>string, unrolled=1, loop_iters=1)</span>
</code></dt>
<dd>
<div class="desc"><p></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>string</code></strong> :&ensp;<code></code></dt>
<dd></dd>
<dt><strong><code>unrolled</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>. Defaults to 1.</dd>
<dt><strong><code>loop_iters</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>. Defaults to 1.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_and_parse(string, unrolled=1, loop_iters=1):
    &#34;&#34;&#34;

    Args:
        string (): 
        unrolled (int, optional): . Defaults to 1.
        loop_iters (int, optional): . Defaults to 1.
    &#34;&#34;&#34;
    if type(string) == ast.BinOp or ast.BoolOp:
        parse_code(astor.to_source(string), &#34;binop_nested&#34;, unrolled)
    if type(string) == ast.Call:
        # cycles += visit(string)
        # latency calculation of traversal
        pass
    if type(string) == ast.Constant:
        parse_code(astor.to_source(string), &#34;constant&#34;, unrolled)</code></pre>
</details>
</dd>
<dt id="nonai_schedule.get_params"><code class="name flex">
<span>def <span class="ident">get_params</span></span>(<span>dfg, area_budget)</span>
</code></dt>
<dd>
<div class="desc"><p></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dfg</code></strong> :&ensp;<code></code></dt>
<dd></dd>
<dt><strong><code>area_budget</code></strong> :&ensp;<code></code></dt>
<dd></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_params(dfg, area_budget):
    &#34;&#34;&#34;

    Args:
        dfg (): 
        area_budget (): 
    &#34;&#34;&#34;
    allocated_area = 0
    while allocated_area &lt; 0.9 * area or allocated_area &gt; 1.2 * area:
        # unroll_params -&gt; modify
        # memory size -&gt; modify
        if area &gt; allocated_area:
            for param in unroll_params:
                # decrease parallelism
                # unroll_params --
                pass
            for mem_cfgs in memory_cfgs:
                # high registers to sram
                # decreases bandwidth
                # update_memory_cfgs
                pass
        # if(area &lt; allocated_area):
    pass</code></pre>
</details>
</dd>
<dt id="nonai_schedule.get_stats"><code class="name flex">
<span>def <span class="ident">get_stats</span></span>(<span>cfg)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_stats(cfg):

    # Write logs
    # * cycle_num,num-of-muls,num-of-adds,num-of-bitwise-ops,num-of-reg-reads,num-of-reg-writes
    #  * If it is called from ScratchpadDatapath, it also outputs per cycle memory
    #  * activity for each partitioned array. add up all the activity of all the components to get the fina
    ddg = {}
    print(&#34;-------------------------------&#34;)
    print(&#34;Generating DDDG&#34;)
    avgpower = 0
    # print(&#34;Num of Nodes:&#34;,  ddg[&#39;nodes&#39;])
    # print(&#34;Num of Edges:&#34;,  ddg[&#39;edges&#39;])
    # print(&#34;Num of Reg Edges:&#34;, regedges)
    # print(&#34;Num of MEM Edges:&#34;, memedges)
    # print(&#34;Num of Control Edges:&#34;, controledges)
    print(&#34;Creating Base Data Path&#34;)
    print(&#34;Cycle :&#34;, cycles)
    print(&#34;Hardware &#34;)
    for keys in hw_utilized.keys():
        avgpower += power[keys][0] * hw_utilized[keys] * latency[keys] / cycles
    print(&#34;Avg Power :&#34;, avgpower)
    # print(&#34;Avg FU Power :&#34;, fupower)
    # print(&#34;Avg FU Dynamic Power:&#34;,fu_dynamic_power)
    # print(&#34;Avg FU leakage Power: &#34;, fu_leakage_power )
    # print(&#34;Avg MEM Power: &#34;, mempower)
    # print(&#34;Avg MEM Dynamic Power: &#34;, mem_dynamic_power)
    # print(&#34;Avg MEM Leakage Power: &#34;, mem_leakage_power)
    # print(&#34;Avg REG Power: &#34;, regpower)
    # print(&#34;Area Calculation :&#34;, area)
    print(hw_allocated, memory_cfgs)</code></pre>
</details>
</dd>
<dt id="nonai_schedule.parse_code"><code class="name flex">
<span>def <span class="ident">parse_code</span></span>(<span>expr, type, unrolled=1, loop_iters=1)</span>
</code></dt>
<dd>
<div class="desc"><p>[Parse the input Python Code file]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>expr</code></strong> :&ensp;<code></code></dt>
<dd></dd>
<dt><strong><code>type</code></strong> :&ensp;<code></code></dt>
<dd></dd>
<dt><strong><code>unrolled</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>. Defaults to 1.</dd>
<dt><strong><code>loop_iters</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>. Defaults to 1.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_code(expr, type, unrolled=1, loop_iters=1):
    &#34;&#34;&#34;[Parse the input Python Code file]

    Args:
        expr (): 
        type (): 
        unrolled (int, optional): . Defaults to 1.
        loop_iters (int, optional): . Defaults to 1.
    &#34;&#34;&#34;
    if type in [&#34;assign&#34;, &#34;expr&#34;, &#34;binop_nested&#34;, &#34;constant&#34;]:
        expr_cycles, hw_need = schedule(expr, type)
        global cycles, hw_allocated, hw_utilized
        cycles += expr_cycles * loop_iters / unrolled
        # hw_allocated = max(hw_need*unrolled, hw_allocated)
        hw_allocated = {
            key: max(value, hw_need[key] * unrolled)
            for key, value in hw_allocated.items()
        }
        hw_utilized = {
            key: value + hw_need[key] * unrolled for key, value in hw_utilized.items()
        }
        print(cycles)</code></pre>
</details>
</dd>
<dt id="nonai_schedule.parse_graph"><code class="name flex">
<span>def <span class="ident">parse_graph</span></span>(<span>graph)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse a non-AI workload graph and store the configuration as a hardware representation</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_graph(graph):
    &#34;&#34;&#34;
    Parse a non-AI workload graph and store the configuration as a hardware representation 
    &#34;&#34;&#34;
    for key in op2sym_map.keys():
        hw_allocated[key] = 0
        hw_utilized[key] = 0
    unroll_params = {}
    variables = {}
    global memory_cfgs

    # if node.operator in lib_common_ops:
    #     common_ops.add(node.operator)
    for node in graph:
        # yield(node)
        for i in node.statements:
            print(i)
            if type(i) == ast.Import:
                continue
            if type(i) == ast.FunctionDef:
                for string in i.body:
                    if isinstance(string, ast.For):
                        continue
                    # print(string)
                    check_and_parse(string)
            if type(i) == ast.Assign:
                # allocated memory/registers
                flag = True
                if isinstance(i.value, ast.Tuple):
                    for x in list(i.value.elts):
                        if not isinstance(x, ast.Constant):
                            flag = False
                    if flag:
                        if isinstance(i.targets[0], ast.Name):
                            variables[i.targets[0].id] = len(list(i.value.elts))
                else:
                    parse_code(astor.to_source(i), &#34;assign&#34;)
            if type(i) == ast.AugAssign:
                # allocated memory/registers
                parse_code(astor.to_source(i), &#34;assign&#34;)
            if type(i) == ast.Expr:
                parse_code(astor.to_source(i), &#34;expr&#34;)
            if type(i) == ast.If:
                check_and_parse(i.test)
            if type(i) == ast.Return:
                check_and_parse(i.value)
            if isinstance(i, ast.For):
                unrolled = 1
                print(ast.dump(i))
                if isinstance(i.iter.args[0], ast.Constant):
                    loop_iters = [i.iter.args[0].value]
                else:
                    print(&#34;Loop iters not captured&#34;)
                    loop_iters = 1
                print(&#34;Loop Iters are&#34;, loop_iters)
                print(&#34;Unrolled are&#34;, unrolled)
                for string in i.body:
                    check_and_parse(string, unrolled)
                # print(ast.dump(i))
                # transform
            # numpy library spmv, dot, conv
    memory_cfgs = variables</code></pre>
</details>
</dd>
<dt id="nonai_schedule.prune_allocator"><code class="name flex">
<span>def <span class="ident">prune_allocator</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prune_allocator():

    # conflict graph
    # interval graph for registers
    if node.operator == &#34;func&#34;:
        getall = []
        for i in func:
            getall.append(allocate_node(i))
    return getall</code></pre>
</details>
</dd>
<dt id="nonai_schedule.schedule"><code class="name flex">
<span>def <span class="ident">schedule</span></span>(<span>expr, type)</span>
</code></dt>
<dd>
<div class="desc"><p>[Schedules the expr from AST]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>expr</code></strong> :&ensp;<code></code></dt>
<dd></dd>
<dt><strong><code>type</code></strong> :&ensp;<code></code></dt>
<dd></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code></code></dt>
<dd></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def schedule(expr, type):
    &#34;&#34;&#34;[Schedules the expr from AST]

    Args:
        expr (): 
        type (): 

    Returns:
        : 
    &#34;&#34;&#34;
    # rescheduleNodesWhenNeeded : (ALAP) rescheduling for non-memory, non-control nodes.
    # upsamplelloops
    # run
    hw_need = {}
    num_cycles = 0
    for key in op2sym_map.keys():
        hw_need[key] = 0
    strs = re.split(regexPattern, expr)
    print(strs, expr)
    if strs.count(&#34;&#34;) &gt; 0:
        strs.remove(&#34;&#34;)
    num_vars = len(strs)
    for i, op in enumerate(op2sym_map.values()):
        hw_need[list(op2sym_map.keys())[i]] += expr.count(op)
        num_cycles += latency[list(op2sym_map.keys())[i]]  # ALAP
    hw_need[&#34;Regs&#34;] = num_vars
    return num_cycles, hw_need</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="nonai_schedule.allocate_memory_cfgs" href="#nonai_schedule.allocate_memory_cfgs">allocate_memory_cfgs</a></code></li>
<li><code><a title="nonai_schedule.check_and_parse" href="#nonai_schedule.check_and_parse">check_and_parse</a></code></li>
<li><code><a title="nonai_schedule.get_params" href="#nonai_schedule.get_params">get_params</a></code></li>
<li><code><a title="nonai_schedule.get_stats" href="#nonai_schedule.get_stats">get_stats</a></code></li>
<li><code><a title="nonai_schedule.parse_code" href="#nonai_schedule.parse_code">parse_code</a></code></li>
<li><code><a title="nonai_schedule.parse_graph" href="#nonai_schedule.parse_graph">parse_graph</a></code></li>
<li><code><a title="nonai_schedule.prune_allocator" href="#nonai_schedule.prune_allocator">prune_allocator</a></code></li>
<li><code><a title="nonai_schedule.schedule" href="#nonai_schedule.schedule">schedule</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>